---
title: "Identifying Characteristics of False Positives from a Flower Detection Network"
author: "Isa Lykke Hansen"
date: "5/15/2020"
output: html_document
---

```{r setup, include=FALSE}
setwd("/Users/isalykkehansen/Desktop/Git/Data-Science-Exam-2020/analysis")
library(pacman)
p_load(tidyverse, cvms, groupdata2, knitr, doParallel, lmerTest, nlme)
set.seed(1991)
```

```{r}
metadata <- read.csv("metadata.csv") 

#find mean Q values for false and true positives
Q_data <- filter(metadata, Q != "NA") %>% 
  group_by(false_pos) %>% 
  summarise(Q_mean = mean(Q))

#assign them to the 73 imgs with missing values:
data <- metadata %>%
  mutate(Q = ifelse(is.na(Q) & false_pos ==1, Q_data$Q_mean[2], Q)) %>% 
  mutate(Q = ifelse(is.na(Q) & false_pos ==0, Q_data$Q_mean[1], Q))

#look at multicollenearity btw variables
multicol <- data %>% 
  select(4:14, -c(location, false_pos))

X<-multicol
library(GGally)
ggpairs(X)

#find all possible combinations of predictors
model_formulas2way = combine_predictors("false_pos", c("size", "ratio", "blur", "ICLS50", "Q"), max_interaction_size = 2)


registerDoParallel(7)


#create folds for cvms (only run once to find best models)
data <- fold(data, k = 10, cat_col = 'false_pos', 
             id_col = 'X')

CV2way <- cross_validate(data, model_formulas2way,
                     fold_cols = '.folds',
                     family = 'binomial',
                     REML = FALSE,
                     parallel = TRUE)

write_csv(CV[1:15], "CV_size_ratio_blur_ICLS50_Q_2way.csv")



#arrange the models in order - best on top
arranged_BA = arrange(CV2way, desc(`Balanced Accuracy`))
arranged_AUC = arrange(CV2way, desc(`AUC`))
arranged_DR  = arrange(CV2way, desc(`Detection Rate`))
#show the whole model and only one metric
select_definitions(arranged_BA, additional_includes = "Balanced Accuracy")
select_definitions(arranged_AUC, additional_includes = "AUC")
select_definitions(arranged_DR, additional_includes = "Detection Rate")


best_model_formulas = reconstruct_formulas(arranged_BA, topn = 100)
```


CV of best 100 models


```{r}
#create folds for cvms
data <- fold(data, k = 10, cat_col = 'false_pos', 
             id_col = 'X', num_fold_cols = 5)

#cross validate on the folds
CV2way <- cross_validate(data, best_model_formulas,
                     fold_cols = c('.folds_1', '.folds_2', '.folds_3', '.folds_4', '.folds_5'),
                     family = 'binomial',
                     REML = FALSE,
                     parallel = TRUE)


arranged_BA = arrange(CV2way, desc(`Balanced Accuracy`))
top100 <- select_definitions(arranged_BA, additional_includes = c("Balanced Accuracy", "AUC"))
top_10 = reconstruct_formulas(arranged_BA, topn = 10)

```

model comparison
```{r}
model_BL <- glm(false_pos ~ 1, family = "binomial", data = data)
model_Q <- glm(false_pos ~ Q, family = "binomial", data = data)
model_best_cv <- glm(false_pos ~ blur * Q + blur * size + ICLS50 * Q + ICLS50 * size + Q * size + ratio * size, family = "binomial", data = data)
model_simple <- glm(false_pos ~ blur + Q + size + ratio, family = "binomial", data = data)
model_cv_simple <- glm(false_pos ~ blur*size + ICLS50*Q + Q*size, family = "binomial", data = data)

anova(model_BL, model_Q, model_simple, model_cv_simple, model_best_cv)

summary(model_best_cv)
AIC(model_best_cv)


model.names <- c("1 Gender", "2 Dept", "3 Gender + Dept")


```



```{r}

loc_0 <- data %>% dplyr::filter(location == "NARS")
loc_1 <- data %>% dplyr::filter(location == "THUL")

# Best model from cross-validation find this first
#maybe by runnning all predictors once and then runnning the best ten models with 10 folds cross validation or smth
model <- glm(false_pos ~ blur*size+ICLS50*Q+Q*size, data=loc_0, family="binomial")

# Get predictions on the loc_0 data
predictions <- data.frame(
  "prediction" = predict(model, newdata = loc_1, type="response"), #probabilities plzzz
  "target" = loc_1$false_pos
)


# Evaluate predictions
eval <- evaluate(predictions, 
                 target_col="target", 
                 prediction_cols="prediction",
                 type="binomial")


```



```{r}
data <- mutate(data, false_pos = as.factor(false_pos))
# Setting up the building blocks
basic_plot <- ggplot(data,
       aes(x = ratio,
           y = size,
           color = false_pos)) +
  theme_bw() +
  labs(x = "Independent variable",
       y = "Dependent variable",
       color = "False Positive")

# Colored scatterplot
basic_plot +
  geom_point(alpha = .3, 
             size = .9) +
  geom_smooth(method = "lm")
```



```{r}
#make location a categorical variable for predition
df_observations <- metadata %>% 
  mutate(location_NARS = as.factor(ifelse(location =="NARS", 1,0)))

df_observations <- arrange(df_observations, img_no) #not meaningfull, ime no != same flower


#create groups automatically (not meaningful for img_no thoug)
df_observations <- group(metadata, n = 'auto', 
                         method = 'l_starts',
                         starts_col = 'false_pos', 
                         col_name = 'session') 


df_observations%>% head(10) %>% kable()


#find only those obs from location NARS
df_obs_subset <-  filter(df_observations, location_num == 0)
model <- glm(false_pos ~ blur, df_obs_subset, family = "binomial")

chi2 <- model$null.deviance - model$deviance
chi2

chidf <- model$df.null - model$df.residual
chidf

chi2.prob <- 1 - pchisq(chi2, chidf)
chi2.prob


logisticpseudoR2s <- function(logisticmodel) {
  deviance <- logisticmodel$deviance #extract model deviance
  nulldeviance <- logisticmodel$null.deviance #extract baseline model deviance
  modelN <- length(logisticmodel$fitted.values) #compute sample size
  R.l <- 1 - deviance/nulldeviance  # Hosmer and Lemeshow's R2 is computed
  R.cs <- 1- exp(-(nulldeviance-deviance)/modelN) # Cox and Snell R2
  R.n <- R.cs / (1 - (exp(-(nulldeviance/modelN)))) # Nagelkerke R2
  cat("Pseudo R2 for logistic regression\n")
  cat("Hosmer & Lemeshow's R2    ", round(R.l,3), "\n")
  cat("Cox and Snell's R2    ", round(R.cs,3), "\n")
  cat("Nagelkerke's R2    ", round(R.n,3), "\n")
}

logisticpseudoR2s(model)

exp(1.281+(8.326e-03)) 

exp(-2.681e-05)

round(inv.logit(1.281+(8.326e-03)),2) 
round(inv.logit(8.326e-03),2) 


```

